{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8Vc2TrNenAtcb/K5fwLa5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adeeba04/DHC-Tasks/blob/main/Housing_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF4I0ZlGFPvi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Load Dataset\n",
        "boston = load_boston()\n",
        "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "y = pd.Series(boston.target, name=\"PRICE\")\n",
        "X_norm = (X - X.mean()) / X.std()\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Linear Regression ---\n",
        "class LinearRegressionScratch:\n",
        "    def __init__(self, lr=0.01, n_iters=1000):\n",
        "        self.lr = lr\n",
        "        self.n_iters = n_iters\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.n_samples, self.n_features = X.shape\n",
        "        self.weights = np.zeros(self.n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            y_pred = np.dot(X, self.weights) + self.bias\n",
        "            dw = (1 / self.n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / self.n_samples) * np.sum(y_pred - y)\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "# --- Random Forest Regressor (simplified) ---\n",
        "class SimpleDecisionTree:\n",
        "    def __init__(self, max_depth=3):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.feature_idx = np.random.randint(0, X.shape[1])\n",
        "        self.threshold = np.median(X[:, self.feature_idx])\n",
        "        self.left_value = y[X[:, self.feature_idx] < self.threshold].mean()\n",
        "        self.right_value = y[X[:, self.feature_idx] >= self.threshold].mean()\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(X[:, self.feature_idx] < self.threshold, self.left_value, self.right_value)\n",
        "\n",
        "class RandomForestScratch:\n",
        "    def __init__(self, n_trees=10, max_depth=3):\n",
        "        self.n_trees = n_trees\n",
        "        self.max_depth = max_depth\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.trees = []\n",
        "        for _ in range(self.n_trees):\n",
        "            idxs = np.random.choice(len(X), len(X), replace=True)\n",
        "            tree = SimpleDecisionTree(max_depth=self.max_depth)\n",
        "            tree.fit(X[idxs], y[idxs])\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = np.array([tree.predict(X) for tree in self.trees])\n",
        "        return np.mean(preds, axis=0)\n",
        "\n",
        "# --- XGBoost-like Model (very simplified) ---\n",
        "class SimpleXGBoost:\n",
        "    def __init__(self, n_estimators=10, learning_rate=0.1):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = learning_rate\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.pred = np.zeros(len(y))\n",
        "        for _ in range(self.n_estimators):\n",
        "            residual = y - self.pred\n",
        "            tree = SimpleDecisionTree()\n",
        "            tree.fit(X, residual)\n",
        "            update = tree.predict(X)\n",
        "            self.pred += self.lr * update\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred = np.zeros(X.shape[0])\n",
        "        for tree in self.trees:\n",
        "            pred += self.lr * tree.predict(X)\n",
        "        return pred\n",
        "\n",
        "# --- Evaluation Function ---\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, name):\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    print(f\"{name} - RMSE: {rmse:.3f}, R2: {r2:.3f}\")\n",
        "    return rmse, r2\n",
        "\n",
        "# --- Run Models ---\n",
        "print(\"\\nEvaluating Models:\\n\")\n",
        "\n",
        "# Linear Regression\n",
        "lr_model = LinearRegressionScratch(lr=0.01, n_iters=1000)\n",
        "evaluate_model(lr_model, X_train.values, X_test.values, y_train.values, y_test.values, \"Linear Regression\")\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestScratch(n_trees=20)\n",
        "evaluate_model(rf_model, X_train.values, X_test.values, y_train.values, y_test.values, \"Random Forest\")\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = SimpleXGBoost(n_estimators=30)\n",
        "evaluate_model(xgb_model, X_train.values, X_test.values, y_train.values, y_test.values, \"XGBoost\")\n",
        "\n",
        "# --- Feature Importance (only Random Forest simulated) ---\n",
        "def plot_feature_importance_random_forest(model, feature_names):\n",
        "    counts = np.zeros(len(feature_names))\n",
        "    for tree in model.trees:\n",
        "        counts[tree.feature_idx] += 1\n",
        "    importance = counts / np.sum(counts)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(feature_names, importance)\n",
        "    plt.title(\"Feature Importance (Random Forest)\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_feature_importance_random_forest(rf_model, X.columns)\n"
      ]
    }
  ]
}